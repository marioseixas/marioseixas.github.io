<!DOCTYPE html>
<html lang="en">    
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>
    
      STF Scraper [script] — infoBAG
    
  </title>

  <link rel="canonical" href="/stf-scraper/">  
  <link rel="alternate" type="application/rss+xml" title="infoBAG" href="//rss.xml">

  <meta property="og:site_name" content="infoBAG">
  <meta property="og:title" content="STF Scraper [script]">
  <meta property="og:type" content="article">
  <meta property="og:url" content="/stf-scraper/">
  
  

  
    <meta property="article:published_time" content="2024-05-01T03:00:00+00:00">
    <meta property="article:author" content="">
  

  
    <meta itemprop="keywords" content="scripts,estudos">
    
      <meta property="article:tag" content="scripts">
    
      <meta property="article:tag" content="estudos">
    
  

  <link href="/style.css" rel="stylesheet">
  <link href="/pagefind/pagefind-ui.css" rel="stylesheet">
  <script src="/pagefind/pagefind-ui.js"></script>
  <script type="module">
    import PagefindHighlight from '/pagefind/pagefind-highlight.js';
    new PagefindHighlight({ highlightParam: "highlight" });
  </script>
  <script src="/assets/js/search.js" defer></script>
  <script src="/assets/js/prism.js" defer></script>
</head>
<body class="post-wrapper">  
  <a class="search-input-block" id="search"></a>
  <article class="post">
  <header>
    <nav aria-label="Main navigation">
  <div class="header-container">
    <a class="internal-link" href="/">
      <img src="https://raw.githubusercontent.com/marioseixas/marioseixas.github.io/main/assets/Sudden_Death_Rune.gif" class="favicon">
    </a>
    <a href="https://ib.bsb.br/archive">
      <img src="https://raw.githubusercontent.com/marioseixas/marioseixas.github.io/main/favicon.ico" class="favicon">
    </a>
    <a href="https://ib.bsb.br/tags">
      <img src="https://raw.githubusercontent.com/marioseixas/marioseixas.github.io/main/assets/Label.gif" class="favicon">
    </a>
    <a href="https://ib.bsb.br/events">
      <img src="https://raw.githubusercontent.com/marioseixas/marioseixas.github.io/main/assets/Paralyse_Rune.gif" class="favicon">
    </a>      
  </div>
    </nav>
  </header>
  <div class="post-heading">
    <h1 class="post-title">STF Scraper [script]</h1>
    <div class="search-link">
        <span>
          <span class="tags">
            <time datetime="2024-05-01T03:00:00+00:00">
              · 01 May 2024
            </time>
            
            &rightarrowtail;
            <time datetime="2024-07-13T13:46:16+00:00">
                13 Jul 2024
              </time>
            
          </span>          
          
            <span>
              · Tags:
              
                <a href="//tags/#scripts" class="tag">scripts</a>,
              
                <a href="//tags/#estudos" class="tag">estudos</a>
              
            </span>
                    
          
            <span class="tags">
              · Edit: aberto.
            </span>
                    
          <a href="https://github.com/marioseixas/marioseixas.github.io/edit/main/_posts/2024-05-01-stf-scraper.md" target="_blank" rel="noopener noreferrer">
            · Improve this
          </a>
          <a href="https://github.com/marioseixas/marioseixas.github.io/commits/main/_posts/2024-05-01-stf-scraper.md" target="_blank" rel="noopener noreferrer">
            · Revision history
          </a>
        </span>
      </div>
      

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><section><code>import json
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

def generate_url(assunto):
    """
    Generates a URL for the 'acordaos' base with the given subject.
    This function constructs a URL string that includes query parameters specifically designed to search within the 'acordaos' section of the STF website.
    """
    return f"https://jurisprudencia.stf.jus.br/pages/search?base=acordaos&amp;sinonimo=true&amp;plural=true&amp;page=1&amp;pageSize=250&amp;queryString={assunto}&amp;sort=_score&amp;sortBy=desc"

def parse_item(html_page):
    """
    Parses the HTML content to extract relevant data from 'acordaos'.
    This function navigates through the HTML structure of the webpage, identifying and extracting necessary details such as the title, ementa, judicial body, and more.
    """
    results = []
    soup = BeautifulSoup(html_page, "html.parser")
    data = soup.find_all("div", class_="result-container")
    for item in data:
        title_element = item.find("h4", class_="ng-star-inserted")
        ementa_element = item.find("span", class_="jud-text ng-star-inserted")
        if title_element and ementa_element:
            title = title_element.text.strip()
            ementa = ementa_element.text.strip()
            dates = item.find_all("span", style="font-weight: normal;")
            turma = dates[0].text.strip() if dates else ""
            ministro = dates[1].text.strip() if len(dates) &gt; 1 else ""
            indexacao_partes = [part.text.strip() for part in item.find_all("p", class_="jud-text m-0")]
            indexacao = indexacao_partes[0] if indexacao_partes else ""
            partes = indexacao_partes[1] if len(indexacao_partes) &gt; 1 else ""
            product = {
                "Title": title,
                "Ementa": ementa,
                "Orgao colegiado": turma,
                "Ministro": ministro,
                "Indexação": indexacao,
                "Partes": partes,
            }
            results.append(product)
    return results

def main(assunto):
    """
    Main function to launch the browser, scrape 'acordaos' data, and save it.
    This function uses the Playwright library to open a browser, navigate to the generated URL, and call the parsing function to extract and save the data.
    """
    url = generate_url(assunto)
    with sync_playwright() as pw:
        browser = pw.chromium.launch(headless=False) 
        page = browser.new_page()
        page.goto(url, wait_until="networkidle")
        parsed = parse_item(page.content())
        print(json.dumps(parsed, indent=3, ensure_ascii=False))
        with open(f"acordaos - {assunto}.json", "w", encoding="utf-8") as file:
            json.dump(parsed, file, indent=3, ensure_ascii=False)
        browser.close()

if __name__ == "__main__":
    assunto = input("Enter the subject for 'acordaos': ")
    main(assunto)
</code></section></div></div>

    <main class="post-content-body"></main>
  </div>
  </article>
  <hr>
  <a href="#" class="back-to-top" aria-label="Back to top">
    <img src="/assets/gold.ico" alt="gold icon">
  </a>
  https://github.com/mvdiogo/stf-web-scraper
</body>  
</html>
