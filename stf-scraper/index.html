<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>
    
      STF Scraper [script] — infoBAG
    
  </title>
  <link rel="canonical" href="https://ib.bsb.br/stf-scraper/">
  <link rel="alternate" type="application/rss+xml" title="infoBAG" href="https://ib.bsb.br/rss.xml">
  
    <meta itemprop="keywords" content="scripts,estudos">
    
      <meta property="article:tag" content="scripts">
    
      <meta property="article:tag" content="estudos">
    
  
  
  <link href="/style.css" rel="stylesheet">
  <link href="/pagefind/pagefind-ui.css" rel="stylesheet">
  <script src="/pagefind/pagefind-ui.js" type="text/javascript"></script>
  <script type="module">
    import PagefindHighlight from '/pagefind/pagefind-highlight.js';
    new PagefindHighlight({ highlightParam: "highlight" });
  </script>
  <script src="/assets/js/search.js" defer></script>
  <script src="/assets/js/prism.js" defer></script>
</head>
<body class="post-wrapper post-content-body">
  <header class="header-container">
    <nav aria-label="Main navigation" class="header-content">
      <a class="internal-link" href="/" aria-label="Home">
        <img src="/assets/Sudden_Death_Rune.gif" alt="Sudden Death Rune" class="favicon">
      </a>
      <a href="https://ib.bsb.br/archive" aria-label="Archive">
        <img src="/favicon.ico" alt="Archive Icon" class="favicon">
      </a>
      <a href="https://ib.bsb.br/tags" aria-label="Tags">
        <img src="/assets/Label.gif" alt="Tags Icon" class="favicon">
      </a>
      <a href="https://ib.bsb.br/events" aria-label="Events">
        <img src="/assets/Paralyse_Rune.gif" alt="Events Icon" class="favicon">
      </a>
    </nav>
    <div class="search-link">
      <div id="search" class="search-input-block"></div>
    </div>
  </header>
  <article class="post content">
    <div class="post-heading">
      <h1 class="post-title">STF Scraper [script]</h1>
      <div class="post-meta">
        <time datetime="2024-05-01T03:00:00+00:00" class="post-date">
          01 May 2024
        </time>
        
          <span class="post-updated">
            &rightarrowtail; Updated: 
            <time datetime="2024-07-13T13:46:16+00:00">
              13 Jul 2024
            </time>
          </span>
        
        
          <div class="post-tags">
            Tags:
            
              <a href="https://ib.bsb.br/tags/#scripts" class="tag">scripts</a>,
            
              <a href="https://ib.bsb.br/tags/#estudos" class="tag">estudos</a>
            
          </div>
        
        
          <div class="post-info">
            Edit: aberto.
          </div>
        
        <div class="post-actions">
          <a href="https://github.com/marioseixas/marioseixas.github.io/edit/main/_posts/2024-05-01-stf-scraper.md" target="_blank" rel="noopener noreferrer" class="btn-primary">
            Improve this page
          </a>
          <a href="https://github.com/marioseixas/marioseixas.github.io/commits/main/_posts/2024-05-01-stf-scraper.md" target="_blank" rel="noopener noreferrer" class="btn-secondary">
            View revision history
          </a>
        </div>
      </div>
    </div>
    <main class="post-content">
      

      <div class="language-plaintext highlighter-rouge"><div class="highlight"><section class="line-numbers" style="white-space: pre-line;"><code>import json
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup

def generate_url(assunto):
    """
    Generates a URL for the 'acordaos' base with the given subject.
    This function constructs a URL string that includes query parameters specifically designed to search within the 'acordaos' section of the STF website.
    """
    return f"https://jurisprudencia.stf.jus.br/pages/search?base=acordaos&amp;sinonimo=true&amp;plural=true&amp;page=1&amp;pageSize=250&amp;queryString={assunto}&amp;sort=_score&amp;sortBy=desc"

def parse_item(html_page):
    """
    Parses the HTML content to extract relevant data from 'acordaos'.
    This function navigates through the HTML structure of the webpage, identifying and extracting necessary details such as the title, ementa, judicial body, and more.
    """
    results = []
    soup = BeautifulSoup(html_page, "html.parser")
    data = soup.find_all("div", class_="result-container")
    for item in data:
        title_element = item.find("h4", class_="ng-star-inserted")
        ementa_element = item.find("span", class_="jud-text ng-star-inserted")
        if title_element and ementa_element:
            title = title_element.text.strip()
            ementa = ementa_element.text.strip()
            dates = item.find_all("span", style="font-weight: normal;")
            turma = dates[0].text.strip() if dates else ""
            ministro = dates[1].text.strip() if len(dates) &gt; 1 else ""
            indexacao_partes = [part.text.strip() for part in item.find_all("p", class_="jud-text m-0")]
            indexacao = indexacao_partes[0] if indexacao_partes else ""
            partes = indexacao_partes[1] if len(indexacao_partes) &gt; 1 else ""
            product = {
                "Title": title,
                "Ementa": ementa,
                "Orgao colegiado": turma,
                "Ministro": ministro,
                "Indexação": indexacao,
                "Partes": partes,
            }
            results.append(product)
    return results

def main(assunto):
    """
    Main function to launch the browser, scrape 'acordaos' data, and save it.
    This function uses the Playwright library to open a browser, navigate to the generated URL, and call the parsing function to extract and save the data.
    """
    url = generate_url(assunto)
    with sync_playwright() as pw:
        browser = pw.chromium.launch(headless=False) 
        page = browser.new_page()
        page.goto(url, wait_until="networkidle")
        parsed = parse_item(page.content())
        print(json.dumps(parsed, indent=3, ensure_ascii=False))
        with open(f"acordaos - {assunto}.json", "w", encoding="utf-8") as file:
            json.dump(parsed, file, indent=3, ensure_ascii=False)
        browser.close()

if __name__ == "__main__":
    assunto = input("Enter the subject for 'acordaos': ")
    main(assunto)
</code></section></div></div>

      
      
    </main>
    <hr>
    <a href="#" class="back-to-top" aria-label="Back to top">
      <img src="/assets/gold.ico" alt="Back to top">
    </a>
    
    <div class="comment-box">
      https://github.com/mvdiogo/stf-web-scraper
    </div>
    
  </article>
  <footer class="post-footer">
    <p>Published on May 1, 2024</p>
    <nav class="post-navigation">
      
      <a href="/whatsappy/" class="previous-post">Previous: WhatsapPY data</a>
      
      
      <a href="/storj-sync/" class="next-post">Next: Rclone: Syncing STORJ Cloud to Local Storage</a>
      
    </nav>
  </footer>
</body>  
</html>
